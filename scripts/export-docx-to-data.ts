import fs from 'fs-extra';
import path from 'path';
import mammoth from 'mammoth';

// Small, standalone extraction script for generating static TS data
// This re-uses parsing logic similar to scripts/import-word-itineraries.ts

function htmlToText(html: string) {
  return html.replace(/<[^>]+>/g, '\n').replace(/\n+/g, '\n').trim();
}

function extractTitle(lines: string[], fileName: string) {
  const titlePatterns = [
    /^(.+?)\s*(?:itinerary|package|cruise|tour)$/i,
    /^(?:itinerary|package|cruise|tour):\s*(.+?)$/i,
    /^(.{10,}?)(?:\s*-\s*\d+\s*days?)?$/i
  ];
  for (const line of lines.slice(0, 8)) {
    for (const pattern of titlePatterns) {
      const match = line.match(pattern);
      if (match && match[1] && match[1].length > 5) {
        return match[1].trim();
      }
    }
  }
  return fileName.replace(/\.[^.]*$/, '').replace(/[-_]/g, ' ');
}

function extractDuration(lines: string[]) {
  const durationPatterns = [/\b(\d+)\s*days?\b/i, /\b(\d+)D\b/i];
  for (const line of lines.slice(0, 6)) {
    for (const pattern of durationPatterns) {
      const match = line.match(pattern);
      if (match) return parseInt(match[1], 10);
    }
  }
  return null;
}

function extractShortDescription(lines: string[]) {
  for (const line of lines) {
    if (line.length > 40 && !/^day\s*\d+/i.test(line)) {
      return line.slice(0, 400);
    }
  }
  return '';
}

function parseDocxHtml(html: string, fileName: string) {
  const text = htmlToText(html);
  const lines = text.split('\n').map(l => l.trim()).filter(Boolean);

  const title = extractTitle(lines, fileName);
  const duration = extractDuration(lines) || undefined;
  const shortDescription = extractShortDescription(lines) || '';

  // very naive date of processing / fallback
  return {
    fileName,
    title,
    duration,
    shortDescription,
    rawLines: lines.slice(0, 400) // keep some preview
  };
}

async function main() {
  const cwd = process.cwd();
  const root = cwd; // repo root
  const files = await fs.readdir(root);
  const docxFiles = files.filter(f => f.toLowerCase().endsWith('.docx') || f.toLowerCase().endsWith('.doc'));

  const extracted: any[] = [];

  for (const f of docxFiles) {
    const full = path.join(root, f);
    try {
      const buffer = await fs.readFile(full);
      const result = await mammoth.convertToHtml({ buffer });
      const parsed = parseDocxHtml(result.value, f);
      extracted.push(parsed);
      console.log('Parsed', f, '->', parsed.title || '(no title)');
    } catch (err) {
      console.error('Failed parse', f, err);
    }
  }

  // Write to src/data/hardcodedItineraries.ts
  const outputDir = path.join(root, 'src', 'data');
  await fs.ensureDir(outputDir);
  const outputFile = path.join(outputDir, 'hardcodedItineraries.ts');

  const tsExport = `// AUTO-GENERATED: Do not edit by hand. Generated by scripts/export-docx-to-data.ts\n\nexport const hardcodedItineraries = ${JSON.stringify(extracted, null, 2)} as const;\n`;

  await fs.writeFile(outputFile, tsExport, 'utf8');
  console.log('Wrote', outputFile, 'with', extracted.length, 'items');
}

if (typeof import.meta !== 'undefined' && (import.meta as any).main) {
  main().catch(err => {
    console.error(err);
    process.exit(1);
  });
}
